{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "  def __init__(self, position, d_model):\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "\n",
    "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    angle_rads = np.zeros(angle_rads.shape)\n",
    "    angle_rads[:, 0::2] = sines\n",
    "    angle_rads[:, 1::2] = cosines\n",
    "    pos_encoding = tf.constant(angle_rads)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "\n",
    "    print(pos_encoding.shape)\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 128)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50,128)\n",
    "\n",
    "plt.pcolormesh(sample_pos_encoding.pos_encoding.numpy()[0],cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0,128))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # query 크기 : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  # key 크기 : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "  # value 크기 : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "  # padding_mask : (batch_size, 1, 1, key의 문장 길이)\n",
    "\n",
    "  # Q와 K의 곱. 어텐션 스코어 행렬.\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "  # 스케일링\n",
    "  # dk의 루트값으로 나눠준다.\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 마스킹. 어텐션 스코어 행렬의 마스킹 할 위치에 매우 작은 음수값을 넣는다.\n",
    "  # 매우 작은 값이므로 소프트맥스 함수를 지나면 행렬의 해당 위치의 값은 0이 된다.\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # 소프트맥스 함수는 마지막 차원인 key의 문장 길이 방향으로 수행된다.\n",
    "  # attention weight : (batch_size, num_heads, query의 문장 길이, key의 문장 길이)\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # output : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "\n",
    "  return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                    [0,10,0],\n",
    "                    [0,0,10],\n",
    "                    [0,0,10]], dtype=tf.float32)\n",
    "temp_v = tf.constant([[1,0],\n",
    "                    [10,0],\n",
    "                    [100,5],\n",
    "                    [1000,6]],dtype=tf.float32)\n",
    "temp_q = tf.constant([[0,10,0]],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_out,temp_attn = scaled_dot_product_attention(temp_q,temp_k,temp_v,None)\n",
    "print(temp_attn)\n",
    "print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0,0,10]],dtype=tf.float32)\n",
    "temp_out,temp_attn = scaled_dot_product_attention(temp_q,temp_k,temp_v,None)\n",
    "print(temp_attn)\n",
    "print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.  0.  0.5 0.5]\n",
      " [0.  1.  0.  0. ]\n",
      " [0.5 0.5 0.  0. ]], shape=(3, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[550.    5.5]\n",
      " [ 10.    0. ]\n",
      " [  5.5   0. ]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10], [0, 10, 0], [10, 10, 0]], dtype=tf.float32) \n",
    "temp_out, temp_attn = scaled_dot_product_attention(temp_q, temp_k, temp_v, None)\n",
    "print(temp_attn) \n",
    "print(temp_out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    # d_model을 num_heads로 나눈 값.\n",
    "    # 논문 기준 : 64\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    # WQ, WK, WV에 해당하는 밀집층 정의\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    # WO에 해당하는 밀집층 정의\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  # num_heads 개수만큼 q, k, v를 split하는 함수\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # 1. WQ, WK, WV에 해당하는 밀집층 지나기\n",
    "    # q : (batch_size, query의 문장 길이, d_model)\n",
    "    # k : (batch_size, key의 문장 길이, d_model)\n",
    "    # v : (batch_size, value의 문장 길이, d_model)\n",
    "    # 참고) 인코더(k, v)-디코더(q) 어텐션에서는 query 길이와 key, value의 길이는 다를 수 있다.\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 2. 헤드 나누기\n",
    "    # q : (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    # k : (batch_size, num_heads, key의 문장 길이, d_model/num_heads)\n",
    "    # v : (batch_size, num_heads, value의 문장 길이, d_model/num_heads)\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 3. 스케일드 닷 프로덕트 어텐션. 앞서 구현한 함수 사용.\n",
    "    # (batch_size, num_heads, query의 문장 길이, d_model/num_heads)\n",
    "    scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "    # (batch_size, query의 문장 길이, num_heads, d_model/num_heads)\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 4. 헤드 연결(concatenate)하기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 5. WO에 해당하는 밀집층 지나기\n",
    "    # (batch_size, query의 문장 길이, d_model)\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x,0),tf.float32)\n",
    "    return mask[:,tf.newaxis,tf.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[[[0. 0. 0. 1. 1.]]]], shape=(1, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 21, 777, 0, 0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(dff, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': padding_mask # 패딩 마스크 사용\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (두번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 인코더는 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 인코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len,seq_len)),-1,0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask,padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1,2,0,4,5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(dff, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "\n",
    "  # 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "\n",
    "  # 패딩 마스크(두번째 서브층)\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 멀티-헤드 어텐션 (첫번째 서브층 / 마스크드 셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs, 'key': inputs, 'value': inputs, # Q = K = V\n",
    "          'mask': look_ahead_mask # 룩어헤드 마스크\n",
    "      })\n",
    "\n",
    "  # 잔차 연결과 층 정규화\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 멀티-헤드 어텐션 (두번째 서브층 / 디코더-인코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1, 'key': enc_outputs, 'value': enc_outputs, # Q != K = V\n",
    "          'mask': padding_mask # 패딩 마스크\n",
    "      })\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 포지션 와이즈 피드 포워드 신경망 (세번째 서브층)\n",
    "  outputs = tf.keras.layers.Dense(units=dff, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 드롭아웃 + 잔차 연결과 층 정규화\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size, num_layers, dff,\n",
    "            d_model, num_heads, dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "\n",
    "  # 디코더는 룩어헤드 마스크(첫번째 서브층)와 패딩 마스크(두번째 서브층) 둘 다 사용.\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 포지셔널 인코딩 + 드롭아웃\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # 디코더를 num_layers개 쌓기\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(dff=dff, d_model=d_model, num_heads=num_heads,\n",
    "        dropout=dropout, name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size, num_layers, dff,\n",
    "                d_model, num_heads, dropout,\n",
    "                name=\"transformer\"):\n",
    "\n",
    "  # 인코더의 입력\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 디코더의 입력\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더의 패딩 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더의 룩어헤드 마스크(첫번째 서브층)\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask, output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 디코더의 패딩 마스크(두번째 서브층)\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더의 출력은 enc_outputs. 디코더로 전달된다.\n",
    "  enc_outputs = encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask]) # 인코더의 입력은 입력 문장과 패딩 마스크\n",
    "\n",
    "  # 디코더의 출력은 dec_outputs. 출력층으로 전달된다.\n",
    "  dec_outputs = decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff,\n",
    "      d_model=d_model, num_heads=num_heads, dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 다음 단어 예측을 위한 출력층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "small_transformer = transformer(\n",
    "vocab_size = 9000,\n",
    "num_layers=4,\n",
    "dff=512,\n",
    "d_model=128,\n",
    "num_heads =4,\n",
    "dropout=0.3,\n",
    "name=\"small_transformer\")\n",
    "\n",
    "tf.keras.utils.plot_model(small_transformer,to_file='small_transformer.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true,y_pred):\n",
    "    y_true = tf.reshape(y_true,shape=(-1,MAX_LENGTH - 1))\n",
    "    \n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,reduction='none')(y_true,y_pred)\n",
    "    mask = tf.cast(tf.not_equal(y_true,0),tf.float32)\n",
    "    loss = tf.multiply(loss,mask)\n",
    "    \n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,d_model,warmup_steps=4000):\n",
    "        super(CustomSchedule,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model,tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    def __call__(self,step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "        \n",
    "        return tf.math.rsqrt(self.d_model) *tf.math.minimum(arg1,arg2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_learning_rate = CustomSchedule(d_model=128)\n",
    "\n",
    "plt.plot(sample_learning_rate(tf.range(200000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n",
    "train_data = pd.read_csv('ChatBotData.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇 샘플의 개수 : 11823\n"
     ]
    }
   ],
   "source": [
    "print('챗봇 샘플의 개수 :', len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for sentence in train_data['Q']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    questions.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = []\n",
    "for sentence in train_data['A']:\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    answers.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12시 땡 !', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "['하루가 또 가네요 .', '위로해 드립니다 .', '여행은 언제나 좋죠 .', '여행은 언제나 좋죠 .', '눈살이 찌푸려지죠 .']\n"
     ]
    }
   ],
   "source": [
    "print(questions[:5])\n",
    "print(answers[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers,target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size],[tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [8178]\n",
      "종료 토큰 번호 : [8179]\n",
      "단어 집합의 크기 : 8180\n"
     ]
    }
   ],
   "source": [
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임의의 질문 샘플을 정수 인코딩 : [5766, 611, 3509, 141, 685, 3747, 849]\n"
     ]
    }
   ],
   "source": [
    "print('임의의 질문 샘플을 정수 인코딩 : {}'.format(tokenizer.encode(questions[20])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 문장 [5766, 611, 3509, 141, 685, 3747, 849]\n",
      "기존 문장 : 가스비 비싼데 감기 걸리겠어\n"
     ]
    }
   ],
   "source": [
    "sample_string = questions[20]\n",
    "\n",
    "tokenized_string = tokenizer.encode(sample_string)\n",
    "print('정수 인코딩 후의 문장 {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer.decode(tokenized_string)\n",
    "print('기존 문장 : {}'.format(original_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5766 ---> 가스\n",
      "611 ---> 비 \n",
      "3509 ---> 비싼\n",
      "141 ---> 데 \n",
      "685 ---> 감기 \n",
      "3747 ---> 걸리\n",
      "849 ---> 겠어\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print('{} ---> {}'.format(ts,tokenizer.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 40\n",
    "def tokenize_and_filter(inputs,outputs):\n",
    "    tokenized_inputs,tokenized_outputs = [],[]\n",
    "    for (sentence1,sentence2) in zip(inputs,outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs,maxlen=MAX_LENGTH,padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs,maxlen=MAX_LENGTH,padding='post')\n",
    "    return tokenized_inputs,tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (11823, 40)\n",
      "답변 데이터의 크기(shape) : (11823, 40)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 7915 4207 3060   41 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "{\n",
    "    'inputs':questions,\n",
    "    'dec_inputs': answers[:,:-1]\n",
    "},\n",
    "{\n",
    "    'outputs':answers[:,1:]\n",
    "},\n",
    "))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      "[[8178 3844   74 7894    1 8179    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "[[3844   74 7894    1 8179    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(answers[0])\n",
    "print(answers[:1][:,:-1])\n",
    "print(answers[:1][:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 8180, 256)\n",
      "(1, 8180, 256)\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "model = transformer(\n",
    "vocab_size = VOCAB_SIZE,\n",
    "num_layers=NUM_LAYERS,\n",
    "dff = DFF,\n",
    "d_model = D_MODEL,\n",
    "num_heads=NUM_HEADS,\n",
    "dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,beta_1=0.9,beta_2=0.98,epsilon=1e-9)\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 256)    3148288     ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 256)    3675648     ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 8180)   2102260     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,926,196\n",
      "Trainable params: 8,926,196\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "185/185 [==============================] - 20s 68ms/step - loss: 1.4513 - accuracy: 0.0308\n",
      "Epoch 2/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 1.1782 - accuracy: 0.0495\n",
      "Epoch 3/50\n",
      "185/185 [==============================] - 13s 71ms/step - loss: 1.0044 - accuracy: 0.0507\n",
      "Epoch 4/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.9316 - accuracy: 0.0543\n",
      "Epoch 5/50\n",
      "185/185 [==============================] - 12s 67ms/step - loss: 0.8752 - accuracy: 0.0572\n",
      "Epoch 6/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.8167 - accuracy: 0.0612\n",
      "Epoch 7/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.7517 - accuracy: 0.0669\n",
      "Epoch 8/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.6778 - accuracy: 0.0749\n",
      "Epoch 9/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.5967 - accuracy: 0.0836\n",
      "Epoch 10/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.5127 - accuracy: 0.0932\n",
      "Epoch 11/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.4264 - accuracy: 0.1040\n",
      "Epoch 12/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.3456 - accuracy: 0.1149\n",
      "Epoch 13/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.2700 - accuracy: 0.1263\n",
      "Epoch 14/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.2039 - accuracy: 0.1365\n",
      "Epoch 15/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.1502 - accuracy: 0.1456\n",
      "Epoch 16/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.1078 - accuracy: 0.1535\n",
      "Epoch 17/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0778 - accuracy: 0.1589\n",
      "Epoch 18/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0596 - accuracy: 0.1622\n",
      "Epoch 19/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0503 - accuracy: 0.1638\n",
      "Epoch 20/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0447 - accuracy: 0.1647\n",
      "Epoch 21/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0418 - accuracy: 0.1649\n",
      "Epoch 22/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.0396 - accuracy: 0.1655\n",
      "Epoch 23/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0361 - accuracy: 0.1661\n",
      "Epoch 24/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0310 - accuracy: 0.1673\n",
      "Epoch 25/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.0276 - accuracy: 0.1681\n",
      "Epoch 26/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0241 - accuracy: 0.1691\n",
      "Epoch 27/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0222 - accuracy: 0.1696\n",
      "Epoch 28/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.0191 - accuracy: 0.1704\n",
      "Epoch 29/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0180 - accuracy: 0.1706\n",
      "Epoch 30/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0163 - accuracy: 0.1711\n",
      "Epoch 31/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0155 - accuracy: 0.1712\n",
      "Epoch 32/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0140 - accuracy: 0.1716\n",
      "Epoch 33/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0128 - accuracy: 0.1720\n",
      "Epoch 34/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0120 - accuracy: 0.1722\n",
      "Epoch 35/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0113 - accuracy: 0.1723\n",
      "Epoch 36/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.0105 - accuracy: 0.1726\n",
      "Epoch 37/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.0099 - accuracy: 0.1727\n",
      "Epoch 38/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0090 - accuracy: 0.1729\n",
      "Epoch 39/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0087 - accuracy: 0.1729\n",
      "Epoch 40/50\n",
      "185/185 [==============================] - 13s 68ms/step - loss: 0.0083 - accuracy: 0.1731\n",
      "Epoch 41/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.0080 - accuracy: 0.1732\n",
      "Epoch 42/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0076 - accuracy: 0.1733\n",
      "Epoch 43/50\n",
      "185/185 [==============================] - 13s 70ms/step - loss: 0.0073 - accuracy: 0.1733\n",
      "Epoch 44/50\n",
      "185/185 [==============================] - 13s 69ms/step - loss: 0.0069 - accuracy: 0.1734\n",
      "Epoch 45/50\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 0.0067 - accuracy: 0.1735\n",
      "Epoch 46/50\n",
      "185/185 [==============================] - 14s 75ms/step - loss: 0.0060 - accuracy: 0.1737\n",
      "Epoch 47/50\n",
      "185/185 [==============================] - 14s 73ms/step - loss: 0.0066 - accuracy: 0.1735\n",
      "Epoch 48/50\n",
      "185/185 [==============================] - 13s 72ms/step - loss: 0.0063 - accuracy: 0.1736\n",
      "Epoch 49/50\n",
      "185/185 [==============================] - 14s 73ms/step - loss: 0.0059 - accuracy: 0.1737\n",
      "Epoch 50/50\n",
      "185/185 [==============================] - 13s 71ms/step - loss: 0.0057 - accuracy: 0.1737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e468dd4070>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    sentence = tf.expand_dims(START_TOKEN + tokenizer.encode(sentence) + END_TOKEN,axis=0)\n",
    "    output = tf.expand_dims(START_TOKEN,0)\n",
    "    \n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence,output],training=False)\n",
    "        \n",
    "        predictions = predictions[:,-1:,:]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions,axis=-1),tf.int32)\n",
    "        \n",
    "        if tf.equal(predicted_id,END_TOKEN[0]):\n",
    "            break\n",
    "        output = tf.concat([output,predicted_id],axis=-1)\n",
    "    return tf.squeeze(output,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    prediction = evaluate(sentence)\n",
    "    \n",
    "    predicted_sentence = tokenizer.decode([i for i in prediction if i < tokenizer.vocab_size])\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "    \n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 영화 볼래?\n",
      "Output: 먼저 고백해 보세요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"영화 볼래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 고민이 있어\n",
      "Output: 저는 생각을 덜하려고 노력해요 .  다른 일에 집중하거나요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"고민이 있어\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 너무 화가나\n",
      "Output: 그럴수록 당신이 힘들 거예요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"너무 화가나\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 카페갈래?\n",
      "Output: 카페 데이트 좋죠 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"카페갈래?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하고싶당\n",
      "Output: 그럴 때가 있어요 .\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하고싶당\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 게임하자\n",
      "Output: 게임하세요 !\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"게임하자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads=8):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.embedding_dim = embedding_dim # d_model\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        assert embedding_dim % self.num_heads == 0\n",
    "\n",
    "        self.projection_dim = embedding_dim // num_heads\n",
    "        self.query_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.key_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.value_dense = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.dense = tf.keras.layers.Dense(embedding_dim)\n",
    "\n",
    "    def scaled_dot_product_attention(self, query, key, value):\n",
    "        matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "        depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        logits = matmul_qk / tf.math.sqrt(depth)\n",
    "        attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, value)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, projection_dim)\n",
    "        query = self.split_heads(query, batch_size)  \n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n",
    "        # (batch_size, seq_len, num_heads, projection_dim)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  \n",
    "\n",
    "        # (batch_size, seq_len, embedding_dim)\n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embedding_dim))\n",
    "        outputs = self.dense(concat_attention)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim, num_heads, dff, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadAttention(embedding_dim, num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [tf.keras.layers.Dense(dff, activation=\"relu\"),\n",
    "             tf.keras.layers.Dense(embedding_dim),]\n",
    "        )\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs) # 첫번째 서브층 : 멀티 헤드 어텐션\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output) # Add & Norm\n",
    "        ffn_output = self.ffn(out1) # 두번째 서브층 : 포지션 와이즈 피드 포워드 신경망\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output) # Add & Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, vocab_size, embedding_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.pos_emb = tf.keras.layers.Embedding(max_len, embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        max_len = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=max_len, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 25000\n",
      "테스트용 리뷰 개수 : 25000\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000  # 빈도수 상위 2만개의 단어만 사용\n",
    "max_len = 200  # 문장의 최대 길이\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "print('훈련용 리뷰 개수 : {}'.format(len(X_train)))\n",
    "print('테스트용 리뷰 개수 : {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 32  # 각 단어의 임베딩 벡터의 차원\n",
    "num_heads = 2  # 어텐션 헤드의 수\n",
    "dff = 32  # 포지션 와이즈 피드 포워드 신경망의 은닉층의 크기\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(max_len,))\n",
    "embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n",
    "x = transformer_block(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "x = tf.keras.layers.Dense(20, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.1)(x)\n",
    "outputs = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "782/782 [==============================] - 20s 24ms/step - loss: 0.3816 - accuracy: 0.8152 - val_loss: 0.3197 - val_accuracy: 0.8718\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 17s 22ms/step - loss: 0.2030 - accuracy: 0.9225 - val_loss: 0.3147 - val_accuracy: 0.8704\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3147 - accuracy: 0.8704\n",
      "테스트 정확도: 0.8704\n"
     ]
    }
   ],
   "source": [
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=2, validation_data=(X_test, y_test))\n",
    "\n",
    "print(\"테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
